{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ffead37-fbda-4ed5-8dbf-980b16418e51",
   "metadata": {},
   "source": [
    "## Q3. Machine Learning Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b737dc5d-19d0-405a-9d82-4fd38afc5951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "\n",
    "# Custom implementation using the most popular sklearn tools\n",
    "from utils import ClassifierGSCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13c7eb2-b4ce-4978-b8da-3e252db843a3",
   "metadata": {},
   "source": [
    "### Goal and Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6244d2-4f84-4cc6-b3af-f38ff3483402",
   "metadata": {},
   "source": [
    "I will implement a custom classifier using **random forests**, **grid search** and **cross validation** for predicting the degree of toxicity. \n",
    "\n",
    "I will **not** try/implement other classifiers as I do not think that proves anything for the sake of the test, \n",
    "\n",
    "I will **not** focus on model performance, I will showcase how I would approach a problem like this in a simple way with a limited amount of time and resources. Why random forests? It is one of the most known classifiers right now, consensually one of the best performers being able to deal with multi-classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "898ec112-d87c-4ede-bfb5-173b8122a02b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flirtation</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>sexually_explicit</th>\n",
       "      <th>threat</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.593828</td>\n",
       "      <td>0.563516</td>\n",
       "      <td>0.849090</td>\n",
       "      <td>0.864632</td>\n",
       "      <td>0.777347</td>\n",
       "      <td>0.602494</td>\n",
       "      <td>Offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.213193</td>\n",
       "      <td>0.407253</td>\n",
       "      <td>0.925010</td>\n",
       "      <td>0.856451</td>\n",
       "      <td>0.456983</td>\n",
       "      <td>0.592931</td>\n",
       "      <td>Offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.474532</td>\n",
       "      <td>0.323574</td>\n",
       "      <td>0.710831</td>\n",
       "      <td>0.747318</td>\n",
       "      <td>0.933715</td>\n",
       "      <td>0.208848</td>\n",
       "      <td>Very offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.503426</td>\n",
       "      <td>0.407557</td>\n",
       "      <td>0.796685</td>\n",
       "      <td>0.854638</td>\n",
       "      <td>0.955973</td>\n",
       "      <td>0.343336</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.394807</td>\n",
       "      <td>0.170078</td>\n",
       "      <td>0.561849</td>\n",
       "      <td>0.766563</td>\n",
       "      <td>0.459300</td>\n",
       "      <td>0.223698</td>\n",
       "      <td>Profanity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   flirtation  identity_attack    insult  severe_toxicity  sexually_explicit  \\\n",
       "0    0.593828         0.563516  0.849090         0.864632           0.777347   \n",
       "1    0.213193         0.407253  0.925010         0.856451           0.456983   \n",
       "2    0.474532         0.323574  0.710831         0.747318           0.933715   \n",
       "3    0.503426         0.407557  0.796685         0.854638           0.955973   \n",
       "4    0.394807         0.170078  0.561849         0.766563           0.459300   \n",
       "\n",
       "     threat           label  \n",
       "0  0.602494       Offensive  \n",
       "1  0.592931       Offensive  \n",
       "2  0.208848  Very offensive  \n",
       "3  0.343336         Neutral  \n",
       "4  0.223698       Profanity  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the data and taking a first look\n",
    "data = pd.read_excel(\"toxicity_xls.xlsx\", engine = \"openpyxl\", index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09532175-f3e1-4d6d-ae9b-ef786c4cff10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flirtation</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>sexually_explicit</th>\n",
       "      <th>threat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12000.000000</td>\n",
       "      <td>12000.000000</td>\n",
       "      <td>12000.000000</td>\n",
       "      <td>12000.000000</td>\n",
       "      <td>12000.000000</td>\n",
       "      <td>12000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.416813</td>\n",
       "      <td>0.438216</td>\n",
       "      <td>0.801580</td>\n",
       "      <td>0.821883</td>\n",
       "      <td>0.556574</td>\n",
       "      <td>0.405262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.185237</td>\n",
       "      <td>0.266264</td>\n",
       "      <td>0.162062</td>\n",
       "      <td>0.095602</td>\n",
       "      <td>0.286541</td>\n",
       "      <td>0.256686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.029391</td>\n",
       "      <td>0.037710</td>\n",
       "      <td>0.024430</td>\n",
       "      <td>0.024729</td>\n",
       "      <td>0.017585</td>\n",
       "      <td>0.026123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.285029</td>\n",
       "      <td>0.232623</td>\n",
       "      <td>0.699709</td>\n",
       "      <td>0.747318</td>\n",
       "      <td>0.305679</td>\n",
       "      <td>0.224373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.403791</td>\n",
       "      <td>0.353419</td>\n",
       "      <td>0.843521</td>\n",
       "      <td>0.821408</td>\n",
       "      <td>0.548136</td>\n",
       "      <td>0.307148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.501138</td>\n",
       "      <td>0.606927</td>\n",
       "      <td>0.936827</td>\n",
       "      <td>0.894143</td>\n",
       "      <td>0.820784</td>\n",
       "      <td>0.497426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.949213</td>\n",
       "      <td>0.993878</td>\n",
       "      <td>0.994336</td>\n",
       "      <td>0.984462</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         flirtation  identity_attack        insult  severe_toxicity  \\\n",
       "count  12000.000000     12000.000000  12000.000000     12000.000000   \n",
       "mean       0.416813         0.438216      0.801580         0.821883   \n",
       "std        0.185237         0.266264      0.162062         0.095602   \n",
       "min        0.029391         0.037710      0.024430         0.024729   \n",
       "25%        0.285029         0.232623      0.699709         0.747318   \n",
       "50%        0.403791         0.353419      0.843521         0.821408   \n",
       "75%        0.501138         0.606927      0.936827         0.894143   \n",
       "max        0.949213         0.993878      0.994336         0.984462   \n",
       "\n",
       "       sexually_explicit        threat  \n",
       "count       12000.000000  12000.000000  \n",
       "mean            0.556574      0.405262  \n",
       "std             0.286541      0.256686  \n",
       "min             0.017585      0.026123  \n",
       "25%             0.305679      0.224373  \n",
       "50%             0.548136      0.307148  \n",
       "75%             0.820784      0.497426  \n",
       "max             1.000000      1.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's describe our data to see if there are any issues that pop\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828a7673-b039-4ea8-898c-e1c6badea449",
   "metadata": {},
   "source": [
    "All features range from 0 to 1 which is a first good indication.\n",
    "Intersting to see that the average for severe_toxicity and insult is quite high, wonder if that will affect the feature relevance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3fd3147-e697-4e58-ab96-9a6c89b40f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flirtation</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>sexually_explicit</th>\n",
       "      <th>threat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>flirtation</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.077118</td>\n",
       "      <td>-0.208650</td>\n",
       "      <td>0.094356</td>\n",
       "      <td>0.795262</td>\n",
       "      <td>0.081217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>identity_attack</th>\n",
       "      <td>-0.077118</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.563307</td>\n",
       "      <td>0.445643</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.178985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insult</th>\n",
       "      <td>-0.208650</td>\n",
       "      <td>0.563307</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.659208</td>\n",
       "      <td>0.036811</td>\n",
       "      <td>-0.068323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>severe_toxicity</th>\n",
       "      <td>0.094356</td>\n",
       "      <td>0.445643</td>\n",
       "      <td>0.659208</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.352226</td>\n",
       "      <td>0.256016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sexually_explicit</th>\n",
       "      <td>0.795262</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.036811</td>\n",
       "      <td>0.352226</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.072997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threat</th>\n",
       "      <td>0.081217</td>\n",
       "      <td>0.178985</td>\n",
       "      <td>-0.068323</td>\n",
       "      <td>0.256016</td>\n",
       "      <td>-0.072997</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   flirtation  identity_attack    insult  severe_toxicity  \\\n",
       "flirtation           1.000000        -0.077118 -0.208650         0.094356   \n",
       "identity_attack     -0.077118         1.000000  0.563307         0.445643   \n",
       "insult              -0.208650         0.563307  1.000000         0.659208   \n",
       "severe_toxicity      0.094356         0.445643  0.659208         1.000000   \n",
       "sexually_explicit    0.795262         0.025000  0.036811         0.352226   \n",
       "threat               0.081217         0.178985 -0.068323         0.256016   \n",
       "\n",
       "                   sexually_explicit    threat  \n",
       "flirtation                  0.795262  0.081217  \n",
       "identity_attack             0.025000  0.178985  \n",
       "insult                      0.036811 -0.068323  \n",
       "severe_toxicity             0.352226  0.256016  \n",
       "sexually_explicit           1.000000 -0.072997  \n",
       "threat                     -0.072997  1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Computing the correlation between all features\n",
    "data.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7896af1d-267a-4451-972a-38b611e878e0",
   "metadata": {},
   "source": [
    "Makes sense that **flirtation** is very positively linearly correlated with **sexually_explicit**.\n",
    "**Identity_attack, insult and severe_toxicity** also have quite a noticeable high correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cce8204-a473-4434-8215-64ca40ef3d32",
   "metadata": {},
   "source": [
    "Depending on the algorithm chosen we might need to get rid of the highly correlation variables as we might introduce a biase or give more weight to that specific behaviour to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c979295-4e69-4850-9a6d-e337f1763121",
   "metadata": {},
   "source": [
    "Our variables are pretty clean already, no need for scaling, outlier analysis, encoding, feature engineering is also not something I see worthy with this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1c6f63-1ac0-44d5-bbd2-ac91a1f2f697",
   "metadata": {},
   "source": [
    "Next I will be using our custom class for training model, please see **utils.py**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbb8e28-5c97-4477-a9a0-0ac232d80cd6",
   "metadata": {},
   "source": [
    "First I will check the target distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f43110d-63cd-48e5-a1ee-a1545373fac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Extremely offensive</th>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hate speech</th>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neutral</th>\n",
       "      <td>814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Offensive</th>\n",
       "      <td>5966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profanity</th>\n",
       "      <td>3430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unknown</th>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Very offensive</th>\n",
       "      <td>1138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     label\n",
       "label                     \n",
       "Extremely offensive    426\n",
       "Hate speech             86\n",
       "Neutral                814\n",
       "Offensive             5966\n",
       "Profanity             3430\n",
       "Unknown                140\n",
       "Very offensive        1138"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(['label']).agg({'label': 'count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4f0be6-fc3f-4279-b3da-1c094ecf5a2e",
   "metadata": {},
   "source": [
    "Clear differences in the distribution, we would probably need to **oversample** some of these labels to make them more representative and \"force\" our model to predict them, I will not cover that here since this is also a question for the \"business\" how important is it to predict the low represented classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf645c7-9b39-40e9-8fc1-5cc9cafb0f11",
   "metadata": {},
   "source": [
    "Now we fit the classifier using my grid search and cross validation implementation:\n",
    "The decision on the best classifier will be **based on the default scoring function from the sklearn implementation of the RandomForestClassifier**. \n",
    "\n",
    "I will **not customize the scoring function**, so the classifier with the **minimal average accuracy for the 5 k-folds will be selected**. \n",
    "\n",
    "In summary **Accuracy** will be our decision metric - there are many more we could use such as **precision** and/or **recall** and would make sense due to the biase we observe in the labels distribution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f82a188-46e1-4b70-86ca-39a05d45eb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise our class from an existing dataframe and the hyperparameters we want to apply grid search for.\n",
    "# The more parameters the more time it will take for the model to be created.\n",
    "# It is important to note that the current implementation will do all the combinations between\n",
    "# all the parameters selected, so the computation time scales exponentially and not linearly as the\n",
    "# number of hyperparameters increase\n",
    "\n",
    "clsf = ClassifierGSCV.from_data(data, n_estimators = [200], max_depth = [None, 50], criterion = ['gini', 'entropy'])\n",
    "clsf.fit_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db7d04af-48ec-42b6-b326-bf90b33365fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.242761</td>\n",
       "      <td>0.195613</td>\n",
       "      <td>0.264093</td>\n",
       "      <td>0.032211</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'n_es...</td>\n",
       "      <td>0.600417</td>\n",
       "      <td>0.615000</td>\n",
       "      <td>0.640417</td>\n",
       "      <td>0.633750</td>\n",
       "      <td>0.441667</td>\n",
       "      <td>0.586250</td>\n",
       "      <td>0.073650</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.081723</td>\n",
       "      <td>0.417538</td>\n",
       "      <td>0.253872</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>gini</td>\n",
       "      <td>50</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'n_esti...</td>\n",
       "      <td>0.597500</td>\n",
       "      <td>0.620417</td>\n",
       "      <td>0.642500</td>\n",
       "      <td>0.632500</td>\n",
       "      <td>0.452500</td>\n",
       "      <td>0.589083</td>\n",
       "      <td>0.069923</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.152425</td>\n",
       "      <td>0.424774</td>\n",
       "      <td>0.253370</td>\n",
       "      <td>0.010818</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'n...</td>\n",
       "      <td>0.604583</td>\n",
       "      <td>0.616250</td>\n",
       "      <td>0.642500</td>\n",
       "      <td>0.628333</td>\n",
       "      <td>0.457083</td>\n",
       "      <td>0.589750</td>\n",
       "      <td>0.067519</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.146311</td>\n",
       "      <td>1.074815</td>\n",
       "      <td>0.269730</td>\n",
       "      <td>0.050840</td>\n",
       "      <td>entropy</td>\n",
       "      <td>50</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'n_e...</td>\n",
       "      <td>0.605000</td>\n",
       "      <td>0.617500</td>\n",
       "      <td>0.647083</td>\n",
       "      <td>0.643750</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.594333</td>\n",
       "      <td>0.069816</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       8.242761      0.195613         0.264093        0.032211   \n",
       "1       8.081723      0.417538         0.253872        0.022000   \n",
       "2      16.152425      0.424774         0.253370        0.010818   \n",
       "3      17.146311      1.074815         0.269730        0.050840   \n",
       "\n",
       "  param_criterion param_max_depth param_n_estimators  \\\n",
       "0            gini            None                200   \n",
       "1            gini              50                200   \n",
       "2         entropy            None                200   \n",
       "3         entropy              50                200   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'criterion': 'gini', 'max_depth': None, 'n_es...           0.600417   \n",
       "1  {'criterion': 'gini', 'max_depth': 50, 'n_esti...           0.597500   \n",
       "2  {'criterion': 'entropy', 'max_depth': None, 'n...           0.604583   \n",
       "3  {'criterion': 'entropy', 'max_depth': 50, 'n_e...           0.605000   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.615000           0.640417           0.633750           0.441667   \n",
       "1           0.620417           0.642500           0.632500           0.452500   \n",
       "2           0.616250           0.642500           0.628333           0.457083   \n",
       "3           0.617500           0.647083           0.643750           0.458333   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.586250        0.073650                4  \n",
       "1         0.589083        0.069923                3  \n",
       "2         0.589750        0.067519                2  \n",
       "3         0.594333        0.069816                1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the results for all the hyperparameters combinations\n",
    "clsf.check_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b989956-b004-4850-81fe-85fe80a7d580",
   "metadata": {},
   "source": [
    "This approach is very resilient to **over fitting**, specially because we are tunning **max depth** and we are using **cross validation**, this might affect the score metrics, in this case the accuracy, other approaches will very likely have higher accuracies but will be worse in a production environment. \n",
    "\n",
    "Note that we got a ~65% accuracy on the second split and a ~44% on split 4, so this performance metric **is very susceptible to random splits of training and testing data**. Not using cross validation will cause your metric to be very **volatile and if you are lucky with your split you get a good accuracy, if you are unlucky you get a low accuracy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1949a954-865e-48ef-85a0-825be904a76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Extremely offensive</th>\n",
       "      <th>Hate speech</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Offensive</th>\n",
       "      <th>Profanity</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Very offensive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.794639</td>\n",
       "      <td>0.190361</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.095000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.161667</td>\n",
       "      <td>0.123333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.805000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.950</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Extremely offensive  Hate speech  Neutral  Offensive  Profanity  Unknown  \\\n",
       "0                0.010         0.00    0.000   0.794639   0.190361    0.000   \n",
       "1                0.000         0.00    0.000   0.880000   0.095000    0.000   \n",
       "2                0.000         0.00    0.000   0.161667   0.123333    0.000   \n",
       "3                0.000         0.00    0.655   0.210000   0.105000    0.000   \n",
       "4                0.000         0.00    0.025   0.070000   0.905000    0.000   \n",
       "5                0.000         0.00    0.000   0.190000   0.805000    0.000   \n",
       "6                0.005         0.00    0.030   0.200000   0.750000    0.000   \n",
       "7                0.950         0.04    0.000   0.010000   0.000000    0.000   \n",
       "8                0.000         0.00    0.010   0.030000   0.960000    0.000   \n",
       "9                0.000         0.00    0.010   0.085000   0.900000    0.005   \n",
       "\n",
       "   Very offensive  \n",
       "0           0.005  \n",
       "1           0.025  \n",
       "2           0.715  \n",
       "3           0.030  \n",
       "4           0.000  \n",
       "5           0.005  \n",
       "6           0.015  \n",
       "7           0.000  \n",
       "8           0.000  \n",
       "9           0.000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I am initializing the classifier again just to show that we can predict without having to \n",
    "# run everything again from scratch, we can start from this point and predict for new data\n",
    "clsf = ClassifierGSCV(simple = True)\n",
    "# Running the prediction for our data top 10 values\n",
    "# I will not run and evaluate for all the data because we already decided what the best model is\n",
    "# I did not save a chunk of the dataset for test because cross validation already does several splits internally\n",
    "# This is just an idea of what the outcome would be, but this would only make sense to evaluate\n",
    "# Either on brand new data or reserved data that the model did not see\n",
    "clsf.predict_classifier(data.iloc[0:10,0:5].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabf0c43-ef4e-4133-8d48-c1065abb24ea",
   "metadata": {},
   "source": [
    "As expected due to the nature of the data set our model will probably **predict very well the most represented labels** - if I had a test data set would be nice to see **how would the model perform against the least represented labels vs the most represented ones**, measuring this on the training/validation might lead to wrong conclusions, I would need a brand new data set to do so, or I would need to save a percentage of the main dataset just for this purpose - I did not do it because I would not change my implementation based on that conclusion, so might as well just perform the training on the entire dataset.\n",
    "\n",
    "Please keep in mind I am speaking about the **testing set**, not the validation set - we had **multiple train and validation splits during the cross validation process**, so there is no issue there!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f488e87d-c8ba-438f-abfe-a6132d5848e9",
   "metadata": {},
   "source": [
    "### Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c8a798-7807-42aa-b957-7718d1156fd0",
   "metadata": {},
   "source": [
    "1. Try different algorithms.\n",
    "2. More Hyperparameter Tunning.\n",
    "3. Create more evaluating metrics specially to evaluate the low represented labels.\n",
    "4. Measure and tackle the impact of having a very biased label distribution (oversample, downsample etc..).\n",
    "5. Deploy the model Implement monitoring\n",
    "6. Run and evaluate the model in new test data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
